---
layout: post
title:  "Government Surveillance - Apple, FBI, Big-Brother"
date:   2017-02-28 10:22:00 -0500
categories: surveillance government FBI warrant spying big data
---


This is a tough one - should companies purposely weaken encryption or place
backdoors in their products for the purposes of government surveillance?  At
first glance, this question receives a clear-cut 'No.' from me.  However, I
whole-heartedly agree with Google chief executive Sundar Pichai that companies
should be required to give law enforcement officials occasional access to user
data.  This is reasonable and necessary should a matter of national security or
public safety involve such information.  The issue with backdoors in a general
sense is that the usage of such a backdoor would be almost completely
unregulated and thus could lead to mass spying, data collection, wire-tapping,
and other 'Big-Brother'-ish sorts of surveillance.  

After reading a few of the articles it becomes clear that this point is
contentious in cases such as the San Bernadino Shooter's iPhone.  If there were
some technical way in which Apple could release his phone's data without
compromising the platform then that should be done to further national
security.  However, they seemed to claim to be unable to do so without making a
sort of 'FBiOS' that could be used in other investigations willingly.  I am
curious as to why Apple doesn't use a vulnerability or weakness in it's OS to
exploit the San Bernadino phone by telling the FBI to not let the device
update, pushing a global iOS update resolving the issue, and then publishing
the weakness so that non-updated devices could be exploited.  This would
include building a private backdoor known only to Apple into the system but
would avoid the possibility that the government obtains free entry 24/7 while
still giving them the needed data.  While I admire the conviction with which
Apple fought the push for decryption of it's product, I find there to be a lack
of foresight by the company in not having a contingency plan for dealing with
decryption that avoides platform compromise should their hand be forced.  This
would have likely deterred the FBI from continuing their push for breaking the
shooter's iPhone on their own, which ultimately led to a method of entry now
private to the FBI which may still not be fixed by Apple.

The Washington Post hits the nail on the head: "The FBI’s myopic focus on this one investigation is understandable, but in the long run, it’s damaging to our national security."  
I am all for our nation being secure and free from the coordinated violence
that may be stopped using appropriate surveillance or investigative techniques,
but having complete free-reign over many citizens' data is unacceptable.  But there
are points to be made against this position that stand out to me and thus I
understand the other side of the coin.  For example, the terrorist attack in
France killing 130 people is said to have been preventable should encrypted
communications used by the perpetrators be made available in real-time to law
enforcement through mandatory decryption.  The balance in these scenarios has
not been reached but perhaps other implementations of technology and heightened
situational awareness can help prevent such incidents (rather than simply
spying).

I don't think Apple or similar
companies are responsible for protecting data or preventing violence through
making data publicly available - they are just a tech company producing
products and services available for sale.  Should a kitchen knife company be
held responsible for helping prevent the use of their products as a weapon?
Clearly not, and the same would go for a coffee mug company were I to use thir
product as some sort of blunt weapon.  General safety regulations must be
followed (i.e. producing safe equipment, machinery, car seats, strollers,
etc.), but ultimately companies are not and should not be held responsible for
the actions of end-users.  Now, in terms of data security, I also do not think
Apple has some sort of moral obligation to protect a user's data.  Although I
personally do not think it is right to have a backdoor installed in your
products to aid government surveillance, it should not be unlawful for a
company to do such a thing.  If Apple wants to focus on the security of its
customer's data and make promises to avoid government intrusion, good for them,
hopefully it helps their business, but they are not obligated to do such
things.

Worries of Big Brother are not simply paranoia but seem to be inflated as of
today.  The security of your precious photos on iCloud is nothing compared to
the necessity of preventing the slaughter of innocent people in our great
country.  However, I defend a companies right to refuse to aid government
surveillance.  National security should trump individual privacy in cases of
gross negligence leading to defraudation of the public on a large scale,
matters of national security, and when lives are at stake - otherwise the mass
aggregation of data on innocent civilians should be avoided.





