---
layout: post
title:  "Artificial Intelligence"
date:   2017-04-03 00:00:00 -0500
categories: turing future economy lifestyle
---

strong, weak, in-between, and narrow v general

Artificial intelligence is formally defined as any sort of computer program
that is able to accomplish a task normally done by humans which is deemed
'intelligent'.  This broad definition from the late 50's can be applied to many
programs we use daily - sorting through difficult mathematical problems,
recognizing images and patterns, and drawing conclusions in task-specific ways
based on large data sets and observations.  AI is already among us!!

This definition, as well as the many impressive feats of recent machine
learning / deep learning efforts such as DeepMind and Watson, is still far from
reaching levels of human intelligence.  This is due to the fact that AI
development has really on made progress in the 'narrow' sense.  Artificial
Intelligence research efforts are divided up into the three philosophies of
strong, weak, and mixed (referring to the strength of correlation between their
implementation with human thought processes).  Further, the general scope of
capability for such programs and machines is classified as narrow or general.
Mixed, narrow AI is responsible for beating a Go champion, winning games of
Jeopardy, and mastering Atari's breakout.  While these accomplishments are both
impressive and useful they still pale in comparison to the beauty and
versatility of the human brain's general intelligence.  One neural network /
deep learning network is practically useless when tested against a task other
than that for which it was previously trained - and each training set
overwrites the capability (or 'memory') of solving previous complex problems.
Also, AI is currently unable to simultaneously receive information and learn,
which is a stark contrast to the human brain.  Ultimately, the current big name
AI projects are certainly a step in the direction towards useful AI, but for
the time being are only machines of narrow intelligence that accomplish few
specialized tasks.

I don't think the Turing Test is a valid measure of intelligence unless one is
able to know with certainty that the test was passed while a participant fully
'understood' the language, not just passed based on things such as pattern
recognition.  Therefore I think the Chinese room is an awesome counter
argument.  If we are able to translate or train based off of large data sets of
information without every fully grasping content, then we should be able to
pass the Turing Test for any sort of language, even those we aren't familiar
with.

As artificial intelligence and automation increase across the country, our
infrastructure and daily activities could very well be redefined.  If
supplemental AI becomes integrated into our society we may see changes in
everything from driving to recalling memories.  However, this is likely not
going to be a concern for long-term security or quality of life, just as
revolutionary inventions such as electricity were slow to catch on and
difficult to originally support.  Dangers will come should cyber-security in
the field be compromised" or take a second class seat to raw research and
result production.  But with recently heightened atmospheres of computer
security and hacking prevention, this should not be an issue.

Also, I personally believe that machine is unable to truly think at any basic
level in the general emotional and reactionary way that human brains are
capable of creating.  Humans are more than just biological computers because we
have self-awareness and feelings such as empathy.  Ethical implications are
huge on both side of this part of the discussion, and include stances on
slowing or halting AI development for the sake of preventing a singularity or
large-scale job-loss and scenarios of human obsoletion.
